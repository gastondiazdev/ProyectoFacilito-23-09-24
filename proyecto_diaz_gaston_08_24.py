# -*- coding: utf-8 -*-
"""Proyecto - Diaz Gaston 08-24.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b2DYEEwVUUpu5I9pSUVbx9jjRZWwtJ5I

## **PROYECTO FINAL**
Diaz Gaston Alejandro - DNI: 32016726

# **1.- Introducción**

Debo expresar que todo lo que continue se expresara a modo hipótetico debido a que nada de lo que se exprese sera real, ya que en el desarrollo de este trabajo se utilizó un dataset obtenido de forma gratuita desde la plataforma web de Kaggle, con datos sobre las ventas de un supermercado. La idea es poder demostrar las habilidades obtenidas de la realizacion del bootcamp de Ciencia de Datos de la 4ta generacion de codigofacilito.

# **2.- Definición de objetivo**#

El Objetivo es armar un modelo que permita predecir el consumo de un cliente segun las condiciones, situacion o atributos del mismo.

# **3.- Conociendo el Dataset**#

Descripción: El presente dataset, es resultado del levantamiento de un estudio de marketing sobre una cantidad importante de personas, con datos de edad, nivel educacional, cituación marital entre otras variables.

Objetivo del analisis: Determinar en función de los datos obtenidos de consumo, la caracterización de las personas más proclives a comprar un producto.

En el presente Dataset se observan un total de 29 columnas (considerando el ID) y un total de 2215 filas, al visualizar las primeras 6 filas se observan los
primeros datos consignados, ordenados por un campo index llamado ID.

Cada columa proporciona detalles específicos sobre los clientes y su consumo. 3 de ellas estan en tipo object que mas tarde trabajaremos, pero antes a modo de indice y consulta hara una breve descripción de cada columna que podria usar.

*   **Una descripción detallada de cada una de las columnas**

Year_Birth = Es un dato tipo entero, contiene los años de nacimiento de las personas encuestadas.

Education = Es un dato tipo texto, contiene el nivel maximo educativo alcanzado por las personas encuestadas.

Marital_Status = Es un dato tipo texto, contiene el estado marital de las personas encuestadas.

Income = Es un dato tipo entero, contiene el ingreso de las personas encuestadas.

Kidhome = Es un dato tipo entero, contiene el número de niños que viven en el mismo hogar que las personas encuestadas.

Teenhome = Es un dato tipo entero, contiene el número de adolescentes que viven en el mismo hogar que las personas encuestadas.

Dt_Customer = Es un dato tipo texto, contiene la fecha en que la persona encuestada fue ingresada a la campaña.

Recency = Es un dato tipo entero, contiene el número de dias de la ultima compra de la persona encuestada.

MntWines = Es un dato tipo entero, contiene el monto gastado en vinos en los ultimos 2 años.

MntFruits = Es un dato tipo entero, contiene el monto gastado en frutas en los ultimos 2 años.

MntMeatProducts = Es un dato tipo entero, contiene el monto gastado en carnes en los ultimos 2 años.

MntFishProducts = Es un dato tipo entero, contiene el monto gastado en fish en los ultimos 2 años.

MntSweetProducts = Es un dato tipo entero, contiene el monto en dulces en los ultimos 2 años.

MntGoldProds = Es un dato tipo entero, contiene el monto en productos etiquetados como premium en los ultimos 2 años.

NumDealsPurchases = Es un dato tipo entero, contiene el número de compras realizadas con un porcentaje de descuento.

*   **Etapa 0: Preparación del ambiente**

Detalle: Se comienza instalando aplicativo, luego importando las librerias y el dataset a utilizar.
"""

#Librerias básica para el analisis
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""**Nota 1: Paso previo, cargar o subir el Set de Datos, en este caso es un archivo de tipo CSV llamado datos-marketing.csv**"""

# Cargando los datos del CSV en un Dataframe
#df_1 = pd.read_csv("C:/Users/GASTON/Desktop/Proyecto/ProjectDiazGaston/datos-marketing.csv", sep = ";")
df_1 = pd.read_csv("/content/datos-marketing.csv", sep = ";")

# Trabajare los datos en una copia
df_marketing = df_1.copy()

#Dimension del dataset
print(df_marketing.shape)

df_marketing.columns

#Tipo de dato para cada columna
df_marketing.dtypes

#Veamos las primeras 6 filas
df_marketing.head(6)

#Veamos las 5 ultimas filas
df_marketing.tail(6)

"""*   **Etapa 1: verificación de la calidad de los datos:**

Antes de comenzar cualquier análisis, se revisan los datos, buscando información faltante; y en caso de existan, decidir qué es lo que se puede realizar con esos registros faltantes. Con los dataframes de pandas, se puede usar la función info() para encontrar datos faltantes.

"""

# Revisión de cuantos valores no nulos existen en cada variable
df_marketing.info()

#Se puede generar una contra validación, esto es revisando comparando la totalidad de registros por columnas
df_marketing.count()

#Antes de proceder con el analisis de los principales conceptos estadísticos, se procede a verificar la estructura de dato corresponde a un dataframe!
type(df_marketing)

"""# **4.- Analisis Exploratorio de Datos (EDA)**#

A continuacion dejo link a pagina para visualizar los datos del dataset en PowerBi:

https://app.powerbi.com/view?r=eyJrIjoiYWU5YmFkNzQtODE0Ny00ZjAzLTg4MmMtMTY2Y2U4MjgxYWUxIiwidCI6ImM5ZDIyNWY0LTlhN2QtNDExNy1hZWQ1LTYwMTI2YjIxOTA0MiIsImMiOjR9

*   **Se procede a analizar el dataset**
"""

df_marketing.describe()

"""*   **Con fines de comparación se evalua la funcion round para visualizar ajustar los datos redondeados versus los sin redondear**

"""

df_marketing.describe().round()

#Histograma
plt.hist(x=df_marketing.Year_Birth, bins=19, edgecolor="black")
plt.title('Histograma de Edad')

#Histograma
plt.hist(x=df_marketing.Kidhome, edgecolor="black")
plt.title('Histograma de Niños en Casa')

#Histograma
plt.hist(x=df_marketing.Marital_Status, edgecolor="black")
plt.title('Histograma de Estado Civil')

#Histograma
plt.hist(x=df_marketing.Education, edgecolor="black")
plt.title('Histograma de Educacion')

#El ingreso "Income" es otra variable identificada como relevante dentro del presente analisis.
est_desc=df_marketing["Income"].describe()
est_desc

plt.scatter(x=df_marketing.Income, y=df_marketing.Year_Birth, edgecolors="white")
plt.xlabel("Ingreso")
plt.ylabel("Año de Nacimiento")
plt.title('Distribución de Edad v/s Ingreso')

"""BREVE CONCLUSION SOBRE LOS CONSUMIDORES...

Los histograma nos demuestra cómo esta distribuida nuestra poblacion de acuerdo a su edad, estado civil, estudios y niños en casa.
La mayor cantidad de nuestros consumidores nacieron entre 1950 y 1990, una buena parte de ellos estan en pareja (Casados o conviviendo) y otra parte viviendos solos (solteros, viudos, divorciados).
Por otro lado, la mayoria de los clientes o bien no tiene niños en casa o solo tiene un niño en casa.
Por ultimo los ingresos  de los consumidores varian, pero en general estan englobados entre 35000 y 70000 pesos.
"""

plt.scatter(x=df_marketing.MntWines, y=df_marketing.Income, edgecolors="white")
plt.xlabel("Consumo de Vino")
plt.ylabel("Ingreso")
plt.title('Distribución de Consumo de Vino v/s Ingreso')

plt.scatter(x=df_marketing.MntMeatProducts, y=df_marketing.Income, edgecolors="white")
plt.xlabel("Consumo de Carnes")
plt.ylabel("Ingreso")
plt.title('Distribución de Consumo de Carnes v/s Ingreso')

plt.scatter(x=df_marketing.MntFishProducts, y=df_marketing.Income, edgecolors="white")
plt.xlabel("Consumo de Pescado")
plt.ylabel("Ingreso")
plt.title('Distribución de Consumo de Pescado v/s Ingreso')

plt.scatter(x=df_marketing.MntSweetProducts, y=df_marketing.Income, edgecolors="white")
plt.xlabel("Consumo de Cosas Dulces")
plt.ylabel("Ingreso")
plt.title('Distribución de Consumo de Cosas Dulces v/s Ingreso')

plt.scatter(x=df_marketing.MntFruits, y=df_marketing.Income, edgecolors="white")
plt.xlabel("Consumo de Frutas")
plt.ylabel("Ingreso")
plt.title('Distribución de Consumo de Frutas v/s Ingreso')

plt.scatter(x=df_marketing.MntGoldProds, y=df_marketing.Income, edgecolors="white")
plt.xlabel("Consumo de Productos de oro")
plt.ylabel("Ingreso")
plt.title('Distribución de Productos de oro v/s Ingreso')

"""Con las visualizaciones anteriores se identifica que productos como el vino o la carne son muy consumidos y en particular la diferencia de cantidades entre los consumidores, el rango o la diferencia de lo minimo y maximo de los que consumen en esos bienes es bastante grande. en cuando a los demas productos las cantidades consumidas es menor y mas concentrado.

---

# **5.- Validando el análisis anterior con dos herramientas automatizada para el EDA**#

Herramienta sweetviz
"""

!pip install sweetviz

import sweetviz as sv

feature_config = sv.FeatureConfig(skip="ID", force_text=["Year_Birth"])
analyze_report = sv.analyze(df_marketing,'Income', feature_config)
analyze_report.show_notebook(w=1000, h=650, scale=0.8)

"""Herramienta Panda Profiling"""

!pip install pandas_profiling

from ydata_profiling import ProfileReport

profile = ProfileReport(df_marketing, title="Reporte en Panda Profiling")

profile.to_file("Supermercado.html")

"""-----

# **6.- Preparando los datos para un proceso de ML**#
"""

#esto lo utilizare despues para subdividir los datos para entrenar y testear
from sklearn.model_selection import train_test_split

#haremos una copia del dataset que veniamos usando
df_marketing_ml = df_marketing.copy()

df_marketing_ml.info()

#Sacare columnas que no usare
df_marketing_ml=df_marketing_ml.drop(['Year_Birth', 'Dt_Customer', 'Recency', 'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth', 'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'Complain', 'Z_CostContact', 'Z_Revenue', 'Response'], axis=1)

df_marketing_ml.info()

#divido el dataset en los parametros y el target que quier alcanzar.
df_marketing_ml_targets = df_marketing_ml.drop(['ID', 'Education', 'Marital_Status', 'Income', 'Kidhome', 'Teenhome'], axis=1)
df_marketing_ml_params = df_marketing_ml.drop(['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds'], axis=1)

df_marketing_ml_params

df_marketing_ml_targets

"""*   **Division del dataset**"""

original_count = len(df_marketing_ml)
training_size = 0.7
test_size = (1 - training_size) / 2

training_count = int(original_count * training_size)
test_count = int(original_count * test_size)
validation_count = original_count - training_count - test_count
print(training_count, test_count, validation_count, original_count)

from sklearn.model_selection import train_test_split
train_x, rest_x, train_y, rest_y = train_test_split(df_marketing_ml_params, df_marketing_ml_targets, train_size=training_count, random_state=42)

test_x, validate_x, test_y, validate_y = train_test_split(rest_x, rest_y, train_size=test_count, random_state=42)

print(len(train_x), len(train_y), len(validate_x), len(validate_y))

"""# **7.- Armando Modelo**#"""

from sklearn.preprocessing import OneHotEncoder

from sklearn.preprocessing import Binarizer

from sklearn.preprocessing import RobustScaler

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import FeatureUnion, Pipeline

one_hot_encoding = ColumnTransformer([
    (
        'one_hot_encode',
        OneHotEncoder(sparse_output=False, handle_unknown="ignore"),
        [
            "Education",
            "Marital_Status"
        ]
    )
])

scaler = ColumnTransformer([
    ("scaler", RobustScaler(), ["Income"])
])

binarizer = ColumnTransformer([
    (
        'binarizer',
        Binarizer(),
        [
            "Kidhome",
            "Teenhome",
        ]
    )
])

one_hot_binarized = Pipeline([
    ("binarizer", binarizer),
    ("one_hot_encoder", OneHotEncoder(sparse_output=False, handle_unknown="ignore")),
])

pipelineando = Pipeline(
    [
        (
            "features",
            FeatureUnion(
                [
                    ("categorical", one_hot_encoding),
                    ("scaled", scaler),
                    ("categorical_binarized", one_hot_binarized),

                ]
            ),
        )
    ]
)

#Siempre sera mi Pipeline, antes de entrenar asi ya lo puedo usar cuando quiera...
pipelineando

pipelineando.fit(train_x)

transform_x = pipelineando.transform(train_x)

train_x.shape

transform_x.shape

"""*   **Entrenando el Modelo**"""

from sklearn.base import clone

pipelineador_transformer = clone(pipelineando)

pipelineador_train_x = pipelineador_transformer.fit_transform(train_x)
pipelineador_validate_x = pipelineador_transformer.transform(validate_x)

from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC

model = RandomForestClassifier(n_estimators=100)

model.fit(pipelineador_train_x, train_y)

"""*   **Validando el Modelo**"""

from sklearn.metrics import accuracy_score, recall_score

pred_y = model.predict(pipelineador_validate_x)

print("accuracy de Prediccion de consumo de Vino:", accuracy_score(validate_y.MntWines, pred_y[:,0]))
print("accuracy de Prediccion de consumo de Frutas:", accuracy_score(validate_y.MntFruits , pred_y[:,1]))
print("accuracy de Prediccion de consumo de Carnes Rojas:", accuracy_score(validate_y.MntMeatProducts , pred_y[:,2]))
print("accuracy de Prediccion de consumo de Pescado:", accuracy_score(validate_y.MntFishProducts , pred_y[:,3]))
print("accuracy de Prediccion de consumo de Productos Dulces:", accuracy_score(validate_y.MntSweetProducts , pred_y[:,4]))
print("accuracy de Prediccion de consumo de Productos de Oro:", accuracy_score(validate_y.MntGoldProds , pred_y[:,5]))

dataset_xfinal = pd.concat([train_x, validate_x])
dataset_yfinal = pd.concat([train_y, validate_y])

dataset_xfinal

dataset_yfinal

pipelineador_xfinal = pipelineador_transformer.fit_transform(dataset_xfinal)

pred_yfinal = model.predict(pipelineador_xfinal)

"""Acuracy de datos de Entrenamiento mas datos de validacion"""

print("accuracy de Prediccion de consumo de Vino:", accuracy_score(dataset_yfinal.MntWines, pred_yfinal[:,0]))
print("accuracy de Prediccion de consumo de Frutas:", accuracy_score(dataset_yfinal.MntFruits , pred_yfinal[:,1]))
print("accuracy de Prediccion de consumo de Carnes Rojas:", accuracy_score(dataset_yfinal.MntMeatProducts , pred_yfinal[:,2]))
print("accuracy de Prediccion de consumo de Pescado:", accuracy_score(dataset_yfinal.MntFishProducts , pred_yfinal[:,3]))
print("accuracy de Prediccion de consumo de Productos Dulces:", accuracy_score(dataset_yfinal.MntSweetProducts , pred_yfinal[:,4]))
print("accuracy de Prediccion de consumo de Productos de Oro:", accuracy_score(dataset_yfinal.MntGoldProds , pred_yfinal[:,5]))

"""GUARDANDO EL MODELO"""

from joblib import dump

dump(pipelineando, "supermarket_pipeline.joblib")